<div align="center">

# PocketAi

### By NextGenX

### The Complete Offline AI Ecosystem for Android

[![Platform](https://img.shields.io/badge/Platform-Android_12%2B-3DDC84?logo=android&logoColor=white)](https://github.com/mithun50/PocketAi-Native)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](LICENSE)

> "Your phone becomes a complete AI workstation: Chat, Voice, Images, and Knowledge‚Äîall running offline with zero compromises."

**The most comprehensive privacy-focused AI ecosystem for mobile devices.** Run LLMs, generate images, use voice AI, inject custom knowledge‚Äîall completely offline. Or seamlessly connect to 100+ cloud models when you need more power. No subscriptions. No data harvesting. Complete control.

[![Get it on APKPure](https://img.shields.io/badge/Get_it_on-APKPure-01C853?style=for-the-badge&logo=android&logoColor=white)](https://apkpure.com/p/com.nxg.pocketai)
 
[GitHub Releases](https://github.com/mithun50/PocketAi-Native/releases/latest) ‚Ä¢ [Join Discord](https://discord.gg/mVPwHDhrAP) ‚Ä¢ [Documentation](https://github.com/mithun50/PocketAi-Native/wiki)
</div>

---

## ‚ö†Ô∏è Project Status Update

> "Sometimes the bravest thing you can do is step back to move forward stronger." 

**Active Development by NextGenX**

PocketAi is the rebranded and actively developed version of the original PocketAi project, now maintained by NextGenX.

**Why I'm pausing:**
- My internship requires my full attention right now, and I need to prioritize it financially
- Managing both my internship and this project simultaneously has become unsustainable
- The mental load of juggling two complex projects has been taking a toll on my health and well-being
- The project needs more maintainers than I can currently provide alone

**What this means:**
- The repository will remain available, and anyone interested in forking and continuing development is more than welcome to do so
- Once my internship situation stabilizes and I have the bandwidth to give this project the attention it deserves, I plan to resume development
- The Discord community remains open for discussions, collaboration, and support

**A heartfelt thank you:**

I'm genuinely grateful to everyone who has supported this project and stuck around. Your interest and contributions have meant a lot to me. I'm sorry I couldn't deliver the complete product as I had hoped, but I believe this pause is necessary for both the project's future and my own health.

If you're interested in maintaining or contributing to a fork, please feel free to reach out via [Discord](https://discord.gg/mVPwHDhrAP). I'd love to see this project continue in some form.

Thank you for understanding.

---

## Overview

PocketAi is the first Android application to combine **Chat AI (LLMs)**, **Image Generation (Stable Diffusion)**, **Voice AI (TTS/STT)**, and **Custom Knowledge Injection (RAG)** in a single, privacy-first package. Everything runs entirely on-device with zero internet dependency, or connect to cloud models for maximum flexibility.

### Core Philosophy

Stop choosing between privacy and power. PocketAi gives you both.

**Three Operating Modes:**

- **üîí Privacy Mode** ‚Äî Execute GGUF models (Llama 3, Mistral, Gemma), generate images with Stable Diffusion 1.5, use voice AI, and inject custom knowledge‚Äîall completely offline. Your data never leaves your phone.
- **‚ö° Power Mode** ‚Äî Access 100+ premium cloud models (GPT-4, Claude 3.5, Gemini, DALL-E) via OpenRouter for complex tasks requiring maximum capability.
- **üîÑ Hybrid Intelligence** ‚Äî Seamlessly switch between offline and cloud modes mid-conversation while preserving full context and conversation history.

---

## What Makes PocketAi Different?

ü§ñ **Complete AI Suite Offline**  
The only mobile app that combines chat, image generation, voice, and knowledge injection‚Äîall running on-device without internet.

üé® **On-Device Image Generation**  
Run Stable Diffusion 1.5 (censored & uncensored) completely offline. Generate images on flights, in remote areas, anywhere.

üß† **RAG Data-Packs**  
Inject Wikipedia dumps, coding documentation, personal notes, or any custom knowledge directly into AI context‚Äîno model retraining required.

üîå **Extensible Plugin System**  
Add web search, content scraping, document analysis, and more. Build your own plugins for unlimited extensibility.

üéôÔ∏è **Premium Offline Voice**  
11 professional TTS voices + Whisper STT‚Äîall running on-device with zero cloud dependencies and near-instant processing.

üåê **100+ Cloud Models**  
When you need maximum power, seamlessly access GPT-4, Claude, Gemini, and 100+ other models via OpenRouter integration.

---

## Key Features

### ü§ñ Dual Inference Engine

**Local Execution**  
Native support for GGUF model formats using llama.cpp. Run models like Llama 3, Mistral, Gemma, Phi, and more entirely on-device with optimized quantization for mobile hardware.

**Cloud Orchestration**  
Unified API integration through OpenRouter provides instant access to 100+ state-of-the-art models without vendor lock-in or multiple subscriptions.

**Intelligent Streaming**  
Real-time token generation with context-aware memory management ensures smooth performance whether running locally or in the cloud.

### üé® On-Device Image Generation

**Stable Diffusion 1.5**  
Full SD 1.5 implementation running completely offline on your phone. Generate high-quality images in 30-90 seconds depending on your device.

**Censored & Uncensored Options**  
Choose between SFW (censored) or uncensored models for artistic freedom and research applications.

**Optimized for Mobile**  
Specially quantized and optimized to run on phones with 6GB+ RAM while maintaining image quality.

### üß† RAG Data-Packs

**Dynamic Knowledge Injection**  
Mount custom datasets (JSON, text, markdown) to enhance AI responses with specialized knowledge without retraining models.

**Use Cases:**
- Inject Wikipedia dumps for educational queries
- Load coding documentation for development assistance
- Add personal notes or company data for context-aware responses
- Import research papers or domain-specific knowledge

**Plugin Integration**  
Data-Packs work seamlessly with both local GGUF models and cloud models for maximum flexibility.

### üéôÔ∏è Premium Voice AI

**Text-to-Speech (TTS)**  
Powered by Sherpa-ONNX, includes 11 professional-grade voices (5 American Female, 2 American Male, 2 British Female, 2 British Male) running entirely on CPU/NPU with zero cloud dependencies.

**Speech-to-Text (STT)**  
Offline Whisper-powered speech recognition for hands-free AI interaction. Perfect for driving, multitasking, or accessibility needs.

**Zero Latency**  
All voice processing happens on-device with near-instantaneous synthesis and recognition.

### üîå Extensible Plugin System

**Available Now:**
- **Web Search** ‚Äî Real-time information retrieval with search engine integration
- **Web Scraper** ‚Äî Extract and inject content from any URL into conversation context
- **DataHub** ‚Äî Mount and manage custom knowledge bases dynamically
- **Document Viewer** ‚Äî Analyze and discuss PDF/text documents with AI

**Coming Soon:**
- Code execution environments
- Advanced image processing pipelines
- Multi-document analysis
- Custom plugin marketplace

### üíæ Advanced Context Management

- **Conversation Persistence** ‚Äî Full chat history with efficient SQLite storage
- **Dynamic Datasets** ‚Äî Attach custom knowledge without model retraining
- **Context Preservation** ‚Äî Switch models mid-conversation without losing thread
- **Export Options** ‚Äî Save conversations, code snippets, and generated images
- **Multi-Session** ‚Äî Manage multiple conversation threads simultaneously

---

## Screenshots

<div align="center">
  <table>
    <tr>
      <td align="center"><b>Chat Interface</b><br/>Multi-modal conversations</td>
      <td align="center"><b>Model Hub</b><br/>100+ models available</td>
      <td align="center"><b>Code Canvas</b><br/>Syntax highlighting & export</td>
      <td align="center"><b>Settings</b><br/>Complete customization</td>
    </tr>
    <tr>
      <td><img src="https://github.com/user-attachments/assets/f4d2c28a-a297-4c08-83e5-391f8bd82d89" width="200" alt="Chat Interface"></td>
      <td><img src="https://github.com/user-attachments/assets/257022d7-8d3b-42a3-97c7-589d8f09fa47" width="200" alt="Model Selection"></td>
      <td><img src="https://github.com/user-attachments/assets/4be156dd-cc55-4eb0-9d89-790f8f11db1e" width="200" alt="Code Canvas"></td>
      <td><img src="https://github.com/user-attachments/assets/2e1c4065-14bb-411b-9021-fc4071a04318" width="200" alt="Settings"></td>
    </tr>
  </table>
</div>

---

## Comprehensive Comparison

| Feature | PocketAi | ChatGPT Mobile | Other AI Apps |
|:--------|:----------:|:--------------:|:-------------:|
| **Offline Chat (LLMs)** | ‚úÖ Full GGUF support | ‚ùå Cloud only | ‚ö†Ô∏è Limited/Basic |
| **Offline Image Generation** | ‚úÖ Stable Diffusion 1.5 | ‚ùå | ‚ùå |
| **Offline Voice (TTS/STT)** | ‚úÖ 11 voices + Whisper | ‚ùå Cloud only | ‚ö†Ô∏è Cloud dependent |
| **Custom Knowledge (RAG)** | ‚úÖ Data-Packs system | ‚ùå | ‚ùå |
| **Plugin Extensibility** | ‚úÖ Open architecture | ‚ùå | ‚ùå |
| **Cloud Model Access** | ‚úÖ 100+ via OpenRouter | ‚úÖ 1 model | ‚ö†Ô∏è Limited options |
| **Uncensored Options** | ‚úÖ User choice | ‚ùå Heavily filtered | ‚ùå Restricted |
| **Privacy Architecture** | ‚úÖ Local-first, zero logging | ‚ùå Server logging | ‚ùå Data harvesting |
| **Pricing Model** | ‚úÖ Free (BYOK optional) | ‚ùå $20/month | ‚ùå $10-60/month |
| **Source Code** | ‚úÖ Apache 2.0 | ‚ùå Proprietary | ‚ùå Closed source |
| **Works Without Internet** | ‚úÖ Full functionality | ‚ùå Useless offline | ‚ö†Ô∏è Very limited |

---

## Installation

### Method 1: APKPure (Recommended)

Visit [PocketAi on APKPure](https://apkpure.com/p/com.nxg.pocketai) for the latest stable release with automatic update notifications.

### Method 2: Direct APK Download

Download the latest release from [GitHub Releases](https://github.com/mithun50/PocketAi-Native/releases/latest) and install `PocketAi-Beta-5.1.apk` on Android 8.0+ devices.

### Method 3: Build from Source

```bash
# Clone repository
git clone https://github.com/mithun50/PocketAi-Native.git
cd PocketAi

# Open in Android Studio (Ladybug or newer)
# Sync Gradle dependencies
./gradlew assembleDebug

# Install on connected device
./gradlew installDebug
```

---

## Quick Start Guide

### üîí Setup for Offline Use (Privacy Mode)

**1. Load a Chat Model (GGUF)**
- Download a GGUF model from [HuggingFace](https://huggingface.co/models) 
  - Recommended: `Llama-3-8B-Q4_K_M.gguf` (4.5GB)
  - Budget: `TinyLlama-1.1B-Q4_K_M.gguf` (669MB)
- Navigate to **Settings ‚Üí Local Models ‚Üí Import Model**
- Select your downloaded GGUF file
- Wait for model to load, then start chatting offline!

**2. Load Image Generation (Stable Diffusion)**
- Download SD 1.5 model (censored or uncensored version)
- Navigate to **Settings ‚Üí Image Models ‚Üí Import SD Model**
- Select model file
- Generate images completely offline!

**3. Enable Voice AI**
- TTS voices are included by default (no download needed)
- For STT: Download Whisper model from **Settings ‚Üí Voice Models**
- Enable voice input in chat interface

**4. Create RAG Data-Packs**
- Prepare your knowledge in JSON/text format
- Navigate to **DataHub ‚Üí Create New Pack**
- Import your data files
- Attach to conversations for enhanced context

### ‚ö° Setup for Cloud Use (Power Mode)

1. Visit [OpenRouter.ai](https://openrouter.ai) and create account
2. Generate an API key (free tier available)
3. In PocketAi: **Settings ‚Üí API Configuration**
4. Enter your OpenRouter API key
5. Access 100+ models instantly (GPT-4, Claude, Gemini, etc.)

### üîÑ Hybrid Mode

Simply switch between local and cloud models mid-conversation:
- Use offline LLM for privacy-sensitive queries
- Switch to GPT-4 for complex reasoning tasks
- Return to offline for continued privacy
- All context is preserved automatically!

---

## System Requirements

### Minimum Specifications
- **Operating System:** Android 8.0+ (API 26)
- **RAM:** 4GB
- **Storage:** 2GB available space
- **Use Case:** Cloud models + basic TTS only

### Recommended for Chat (Local GGUF)
- **Operating System:** Android 10+
- **RAM:** 6GB+ (8GB preferred)
- **Processor:** Snapdragon 8 Gen 1 / Dimensity 8100 or equivalent
- **Storage:** 5GB+ available space
- **NPU:** Optional but improves performance significantly

### Recommended for Image Generation
- **Operating System:** Android 11+
- **RAM:** 8GB minimum (12GB preferred)
- **Processor:** Snapdragon 8 Gen 2 or equivalent flagship
- **Storage:** 8GB+ available space (for SD models)
- **Generation Time:** 30-90 seconds depending on device

### Optimal Configuration (Everything Offline)
- **RAM:** 12GB+
- **Processor:** Snapdragon 8 Gen 3 or equivalent
- **Storage:** 10GB+ free space
- **Experience:** Smooth chat + image generation + voice AI

---

## Development Roadmap

### ‚úÖ Q4 2024 - Q1 2025: Foundation (CURRENT)
- ‚úÖ GGUF model support with llama.cpp
- ‚úÖ 11 offline TTS voices via Sherpa-ONNX
- ‚úÖ OpenRouter cloud integration (100+ models)
- ‚úÖ Plugin system (Web Search, Scraper, DataHub)
- ‚úÖ RAG Data-Packs for knowledge injection
- üöß Stable Diffusion 1.5 offline image generation
- üöß Offline Whisper STT integration

### Q2 2025: Expansion
- Multi-voice TTS conversations (different voices for different characters)
- Advanced code export with syntax highlighting
- Desktop companion app (Windows/Linux sync)
- Enhanced plugin marketplace
- Vector database for long-term memory

### Q3 2025: Advanced Features
- Multi-modal vision models (LLaVA, GPT-4V integration)
- TFLite and ONNX runtime support
- On-device video analysis
- Collaborative AI sessions
- Custom model fine-tuning tools

### Q4 2025: Ecosystem Maturity
- Cross-platform synchronization (phone ‚Üî desktop)
- Community plugin marketplace
- Advanced RAG with semantic search
- Enterprise deployment options
- API for third-party integration

---

## Use Cases

### üë®‚Äçüíª For Developers
- Test prompts and APIs without cloud costs during development
- Run coding assistants offline on flights or with poor connectivity
- Inject documentation into RAG for context-aware code help
- Generate UI mockups and diagrams with SD
- Privacy-first development environment

### üîê For Privacy Advocates
- Zero data leaves your device in offline mode
- Verify privacy claims (open-source Apache 2.0)
- No tracking, no telemetry, no server logging
- Full control over your AI interactions
- Uncensored options for research and legitimate use

### ‚úàÔ∏è For Travelers
- Full AI capability on flights (no WiFi needed)
- Works in remote areas with no connectivity
- No roaming data costs for AI queries
- Generate travel content (images, itineraries) offline
- Voice translations without cloud latency

### üé® For Content Creators
- Generate images for social media posts anywhere
- Brainstorm content ideas with AI offline
- Create variations and iterations without API limits
- No subscription costs eating into creator budgets
- Uncensored artistic freedom

### üéì For Students & Researchers
- Free access to cutting-edge AI models
- Study AI without expensive subscriptions
- Load research papers into RAG for analysis
- Generate diagrams and visualizations
- Privacy for sensitive academic work

---

## Technical Architecture

PocketAi implements modern Android development patterns with a hybrid native/Kotlin architecture:

**Core Technologies:**
- **Language:** Kotlin (UI/Logic) + C++ (Inference engines)
- **UI Framework:** Jetpack Compose (declarative, reactive UI)
- **Local Inference:** llama.cpp (GGUF models) + JNI bindings
- **Image Generation:** Stable Diffusion C++ implementation
- **TTS Engine:** Sherpa-ONNX (neural voices)
- **STT Engine:** Whisper via Sherpa-ONNX
- **API Layer:** Retrofit + OkHttp (cloud models)
- **Database:** Room (SQLite wrapper) for conversations
- **Async Operations:** Kotlin Coroutines + Flow
- **Dependency Injection:** Hilt/Dagger

**Performance Optimizations:**
- Quantized model support (Q4_K_M, Q5_K_S, etc.)
- Context caching for faster inference
- Memory-mapped model loading
- NPU acceleration where available
- Efficient token streaming
- Background processing with WorkManager

---

## Contributing

We welcome contributions from developers, researchers, AI enthusiasts, and privacy advocates!

### How to Contribute

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes with descriptive messages
4. **Push** to your branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request with detailed description

### Priority Areas

**High Priority:**
- üêõ Bug reports and fixes (especially device-specific issues)
- üìö Documentation improvements and translations
- üß™ Testing on various Android devices and chipsets
- üîå New plugin development
- üé® UI/UX enhancements

**Medium Priority:**
- üåç Internationalization (i18n) - help us support more languages
- ‚ôø Accessibility improvements
- üìä Performance optimizations
- üéì Tutorial content and guides

**Feature Requests:**
- Check existing issues before creating new ones
- Provide clear use cases and examples
- Be patient - we're a small team!

### Development Guidelines

- Follow Kotlin coding conventions
- Write meaningful commit messages
- Test on real devices when possible
- Document new features
- Respect user privacy in all contributions

---

## License

Distributed under the **Apache 2.0 License**. See [`LICENSE`](LICENSE) for complete terms.

**What this means:**
- ‚úÖ **Commercial use** - Use in commercial products
- ‚úÖ **Modification** - Modify and create derivatives
- ‚úÖ **Distribution** - Distribute freely
- ‚úÖ **Patent use** - License includes patent rights
- ‚úÖ **Private use** - Use privately without restrictions

**Requirements:**
- üìÑ Include license and copyright notice
- üìù Document any changes made
- üîì Make source available if distributing

---

## Acknowledgments

> "If I have seen further, it is by standing on the shoulders of giants." ‚Äî Isaac Newton

PocketAi would not be possible without these exceptional open-source projects:

- **[llama.cpp](https://github.com/ggerganov/llama.cpp)** by Georgi Gerganov ‚Äî Efficient LLM inference in pure C/C++
- **[Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx)** ‚Äî Premium offline speech synthesis and recognition
- **[Stable Diffusion](https://github.com/CompVis/stable-diffusion)** ‚Äî Revolutionary text-to-image generation
- **[OpenRouter](https://openrouter.ai)** ‚Äî Unified API gateway for 100+ AI models
- **[Jetpack Compose](https://developer.android.com/jetpack/compose)** ‚Äî Modern declarative UI for Android
- **[HuggingFace](https://huggingface.co)** ‚Äî Community and models that make AI accessible

Special thanks to the open-source AI community for making privacy-respecting AI possible.

---

## Support & Community

### Get Help & Connect

- üí¨ **[Discord Community](https://discord.gg/mVPwHDhrAP)** ‚Äî Real-time chat, support, and discussions
- üêõ **[Issue Tracker](https://github.com/mithun50/PocketAi-Native/issues)** ‚Äî Report bugs or request features
- üí° **[GitHub Discussions](https://github.com/mithun50/PocketAi-Native/discussions)** ‚Äî Technical questions and ideas
- üìß **Email:** [Support](mailto:support@nextgenx.dev) ‚Äî For private inquiries

### Stay Updated

- ‚≠ê **Star this repository** to show support and get updates
- üëÄ **Watch releases** for new features and updates
- üê¶ **Follow on Twitter** [@PocketAi](#) ‚Äî News and announcements
- üì± **APKPure** ‚Äî Automatic update notifications

---

## FAQ

**Q: Will this drain my battery?**  
A: Local inference is power-intensive. For long sessions, keep your phone plugged in. Cloud mode uses minimal battery.

**Q: How big are the model files?**  
A: GGUF models: 0.5GB-8GB depending on model size. SD 1.5: ~2GB. TTS/STT: 50-500MB.

**Q: Can I use my own API keys?**  
A: Yes! BYOK (Bring Your Own Key) for OpenRouter. You control costs and usage.

**Q: Is my data really private?**  
A: In offline mode, absolutely nothing leaves your device. Verify in our open-source code.

**Q: Why not just use ChatGPT?**  
A: PocketAi gives you choice, privacy, offline capability, uncensored options, and zero subscriptions.

**Q: Does it support iOS?**  
A: Not currently. Android only due to technical constraints of iOS.

**Q: Can I monetize apps built with this?**  
A: Yes! Apache 2.0 license allows commercial use.

---

<div align="center">

**Built with ‚ù§Ô∏è by [NextGenX](https://github.com/mithun50) and the Open Source Community**

*Privacy-first AI for everyone, everywhere*

If PocketAi empowers your AI journey, please ‚≠ê star the repository!

[Download](https://apkpure.com/p/com.nxg.pocketai) ‚Ä¢ [Report Bug](https://github.com/mithun50/PocketAi-Native/issues) ‚Ä¢ [Request Feature](https://github.com/mithun50/PocketAi-Native/issues) ‚Ä¢ [View Roadmap](https://github.com/mithun50/PocketAi-Native/projects) ‚Ä¢ [Join Discord](https://discord.gg/mVPwHDhrAP)

---

**Made possible by llama.cpp ‚Ä¢ Sherpa-ONNX ‚Ä¢ Stable Diffusion ‚Ä¢ OpenRouter ‚Ä¢ Jetpack Compose**

</div>
